# Metal 计算管道

<Wisdom
  words="相反，如果是这样的话，也可能是这样；如果是这样的话，那就是这样了；但既然不是，那就不是。这就是逻辑。"
  author="刘易斯·卡罗尔"
/>

Metal 的一大承诺是它允许程序员进行通用 GPU 编程（GPGPU 编程）。多年来，随着 GPU 变得越来越强大，聪明的程序员已经意识到他们可以将大量不一定与图形相关的工作卸载到 GPU。本章重点介绍 Metal 中的 GPGPU 编程。

### Metal 框架概念

尽管本章专门讨论 GPGPU 编程，但前面的许多章节介绍了你在阅读本章之前需要熟悉的概念。如果你的主要兴趣是 GPGPU 编程并且直接跳到本章，请在继续之前浏览这些章节：

- 第 4 章，“图形基础数学”
- 第 5 章，“着色器简介”
- 第 6 章，“ Metal 资源和内存管理”
- 第 7 章，“库、函数和管道状态”

## GPU 编程简介

在过去 10 年里，GPU 编程已成为吞吐量和速度的流行词 GPU 编程到底是什么？为什么它这么快？这个难题的第一部分是了解 GPU 与 CPU 的区别。

_中央处理单元 (CPU)_ 是计算机的大脑。它负责你计算机上的所有内容 CPU 的很大一部分必须专用于片上高速缓存。因此，CPU 只能将有限的空间分配给计算逻辑 GPU 具有更加专业化的灵活性 GPU 最大限度地利用了计算逻辑的可用空间。

GPU 通过算术逻辑单元 (ALU) 最大化其空间 ALU 是执行算术和按位运算的组合数字电子电路。在 CPU 上，这些运算主要是整数二进制数。在 GPU 上，这些运算主要是浮点数。我们人类对数学运算的看法与计算机不同。对我们来说，两个数字相乘是一次操作，但对计算机来说，它涉及位级别的多个操作。通过拥有宽内存总线和许多 ALU，GPU 可以一次获取更多操作，如图 15.1 所示。通过扩展，GPU 在处理大量操作时比仅处理一两个操作更高效。

<Figure src={require("../figures/042.jpg")} num="15.1" desc="ALU 并行处理" />

CPU 每个芯片上的内核数量也有限。拥有多个内核使得芯片能够实现并行编程。每个内核一次只能完成一项任务，因此双核处理器在任何给定时间点执行的工作量是单核处理器的两倍。然而，多个核心会增加复杂性，因为核心必须协调它们处理任务的方式，而不覆盖两个核心正在访问的内存。

GPU 将这种并行处理提升到了一个新的水平 GPU 不限于两个、四个甚至十几个核心，而是拥有数千个核心。因此，GPU 可以同时执行数千个命令。这种设计实现了令人难以置信的快速性能，但它也需要程序员进行大量的协调和组织。

## 并发与并行

关于并发和并行之间的区别存在一些混淆。它们有时可以互换使用，但它们是不同的概念。

如果你曾经暂停过 Xcode 模拟器中运行的程序并查看堆栈跟踪，则会发现在任何给定时间通常都有大约 16 个线程在运行。你没有创建这些线程——它们是由 Cocoa 框架在幕后实现的。这些线程并非同时进行处理。

假设你是一名独立游戏开发者。在任何一天，你都可以编写代码、设计艺术品和营销，但你无法同时完成所有这些事情。你正在同时执行这些操作。你就像一个运行三个线程工作的 CPU，但一次只能执行一个。

假设你雇用某人来创作你的艺术品。让别人免费创作艺术品

你可以去做其他工作了。如果你让艺术家与你并行工作，你可以优化这种安排，这样当你的其他工作完成并且你准备好你的艺术作品时，它已经在等着你了。

由于你一次只能执行一个线程，因此通过将工作委托给美工人员可以提高效率。现在想象一下，你有一个完整的艺术家工作室，他们可以同时处理游戏的不同部分 GPU 就像那个动画工作室。由于 GPU 有数千个核心，因此可以发送到 GPU 的工作越多，可以同时完成的工作就越多，如图 15.2 所示。

<Figure src={require("../figures/043.jpg")} num="15.2" desc="并发与并行" />

你可能想知道如果在任何给定时刻只能执行一项任务，为什么还要有多个线程。不同的任务可以放在具有不同优先级的不同线程上。你很熟悉不要将所有工作都放在主线程上的警告。主线程的优先级是用户交互。在网络调用完成之前，你不想阻止用户交互。任何非用户界面函数调用都可以放在优先级较低的后台线程上。

Apple 的 Grand Central Dispatch (GCD) 框架监视所有线程并安排工作。它检查用户是否正在与应用程序交互。如果用户开始交互，

GCD 停止所有其他工作来处理主线程的要求。一旦工作完成，GCD 就可以回去安排其他任务在后台完成 A9 芯片功能如此强大，以至于所有这一切都可以无缝地进行，而用户无需意识到幕后发生的所有资源处理。

你可以使用许多编程模型来创建并行性。并行性可以构建到计算机体系结构、数据级别和指令级别 GPU 是建立在数据并行性之上的 CPU 并行性超出了本书的范围，但主要内容是 GPU 的并行性远远高于 CPU，并且向 GPU 发送工作可以给你带来巨大的性能优势。

## 使用 GPU 进行一般计算

你可能会遇到的一个大问题是，GPU 可以执行哪些工作？你知道你无法将网络调用发送到 GPU 进行处理，因为 GPU 不执行此类工作。那么它可以做什么类型的工作呢？

GPU 旨在并行执行大量数学运算。例如，这需要将 1,000 个元素的数字数组中的每个元素乘以 2。它还需要将矩阵乘法和矩阵运算应用于大型数据集。许多科学和数学学科都是建立在线性代数概念的基础上的。这些包括但不限于以下内容：

- 2D 和 3D 计算机图形学
- 图像处理
- 密码学
- 马尔可夫链
- 神经网络
- 经济学

任何可以在矩阵中处理的数学运算都可以在 GPU 上并行执行。任何需要对每个成员执行一致操作的大型数据集都可以在 GPU 上执行 GPU 不能很好地处理条件逻辑，因此应不惜一切代价避免使用大量 if/else 语句的操作。

要了解哪些操作可以在 GPU 上轻松执行，请查看 Metal Shading Language 规范。至于你将其应用到什么学科，那取决于你。数学是许多科学学科的基础，因此不要将自己局限于互联网上的常见用例。

## 内核函数

在第 5 章“着色器简介”中，你熟悉了顶点和片段着色器。还有另一种类型的着色器函数：内核着色器，仅适用于 Metal 计算程序。与 3D 图形程序不同，使用计算程序时，你不必担心渲染问题。你没有需要转换的顶点数据缓冲区

对象空间到世界空间，因此你不需要单独的顶点着色器将顶点数据提供给内核着色器。在许多方面，计算管道比图形渲染管道简单得多。

内核函数也是唯一为数据并行计算而设置的 `MTLFunction` 类型。正如“并发与并行”部分中所讨论的，GPU 拥有数千个核心。核函数可以在 1 维、2 维或 3 维网格上执行计算。

内核函数还必须具有 void 返回类型。顶点和片段函数存在于渲染管道上，这意味着每个函数的结果必须返回并传递到管道的下一部分。内核函数不返回输出。它们对值缓冲区应用数学运算，并且可以就地处理。

这是内核函数签名的典型示例：

kernel void kernel_function(texture2d inTexture [[texture(0)]],texture2d outTexture [[texture(1)]], uint2 gid [[thread_position_in_grid]]) { }

该函数必须以名称 kernel 开头，以区别于顶点函数或片段函数。返回类型必须为 void。接下来是内核函数的名称。与处理其他类型的函数一样，你可以将参数表中的参数位置作为参数传递给内核函数。

## Metal 计算命令编码器

发送到 GPU 的所有工作都被编码到 MTLCommandEncoder 实例中。有四种不同类型的命令编码器。到目前为止，在本书中，你已经学会了如何使用其中三个。本章介绍第四个也是最后一个：Metal 计算命令编码器（MTLComputeCommandEncoder）。

设置 MTLComputeCommandEncoder 比像任何其他对象一样简单地实例化它要复杂一些。它需要几个步骤并首先设置一些其他对象：

var 设备：MTLDevice！ var commandQueue: MTLCommandQueue! var 库：MTLLibrary！

func setupMetal() { 设备 = MTLCreateSystemDefaultDevice() commandQueue = device.makeCommandQueue() 库 = device.newDefaultLibrary() }

设置 MTLComputeCommandEncoder 的方法 makeComputeCommandEncoder() 存在于 MTLCommandBuffer 对象上 MTLCommandBuffer 对象由 MTLCommandQueue 上的 makeCommandBuffer() 方法初始化 MTLCommandQueue 又由 MTLDevice 上的 makeCommandQueue() 方法创建。因此，要初始化 MTLComputeCommandEncoder，你需要设置一系列其他 Metal 对象，所有这些对象都会初始化链中的下一个。

将这三个对象全部初始化并就位后，你可以调用 MTLCommandBuffer 上的方法来初始化 MTLComputeCommandEncoder：

让 commandBuffer = commandQueue.makeCommandBuffer() 让 computeEncoder = commandBuffer.makeComputeCommandEncoder()

乍一看这可能有点令人困惑，但无论如何，这些都是你需要创建的对象实例。尝试将其视为健全性检查，以确保你正确设置对象。

### 创建计算管道状态

正如你对渲染管道所做的那样，你可以在此处为计算管道创建管道状态。在对 GPU 进行编程时，尽可能多地预先设置是提高效率的最佳方法。第一步是创建计算管道状态变量：

varcomputePipelineState：MTLComputePipelineState！

创建该变量后，你需要对其进行设置：

func setupPipeline() { if letcomputeFunction = library.makeFunction( name:computeFunctionName) { do {computePipelineState = try device.makeComputePipelineState(function:computeFunction) } catch let error as NSError { fatalError("Error: \(error.localizedDescription)" ) } } else { fatalError("运行时未找到内核函数") } }

设置状态所需的唯一部分是内核函数。你需要使用此函数来设置供管道状态使用的 Metal 库。如果由于某种原因你无法设置该库，你需要确保程序失败。最后，你需要将状态编码到计算管道中。

computeEncoder.setComputePipelineState(computePipelineState)

到目前为止，一切都有些熟悉了。接下来，你将学习如何设置并行工作组，这是计算编码器独有的功能。

## 发布工作网格

本节介绍如何在 GPU 上设置并行处理。你可以控制一些移动部件，使你能够自定义工作的处理方式。你在这方面所做的选择会对你能够从 GPU 获得的性能产生重大影响。

在 GPU 上执行的任务有点类似于你必须完成的任何大型项目。该项目可以分解为离散的任务，由一组中的不同参与者完成。作为 GPU 项目经理，你的部分工作是确定完成这项工作所需的最佳人员数量以及如何在这些参与者之间分配这些任务。

### 线程组

执行工作的各个单元称为 _线程_。线程是以下集合之一

通过调度命令在设备上调用的内核函数的并行执行。线程通过其在网格中的线程位置和线程组中的线程位置来与集合中的其他执行区分开来。

GPU 对 GPU 上的每个线程进行微观管理的效率并不高。相反，它们被组装在 _线程组_ 中。线程由一个或多个处理元素作为在计算单元上执行的线程组的一部分来执行，如图 15.3 所示。它们还共享一个指令指针，这意味着它们都同时执行相同的指令。线程组上可以执行的线程数就是 _线程执行宽度_。与计算机科学中的许多概念一样，最大执行宽度是 2 的幂。它根据你使用的 iPhone 版本而变化。功能更强大的 iPhone 具有更深的执行宽度。第 16 章“ Metal 图像处理”中探讨了这个概念。

<Figure
  src={require("../figures/044.jpg")}
  num="15.3"
  desc="在管道中执行的线程"
/>

首先，你需要线程组大小和线程组宽度的属性：

var threadgroupSize，threadsPerThreadgroup：MTLSize！

接下来，你需要计算线程组大小和线程组宽度有多大：

func setupThreads() { let threadgroupWidth = 8 let μ = side / threadgroupWidth + (side == threadgroupWidth? 0 : 1)

threadgroupSize = MTLSize（宽度：μ，高度：μ，深度：1）threadsPerThreadgroup = MTLSize（宽度：threadgroupWidth，高度：threadgroupWidth，深度：1）}

最后，你需要将它们编码到计算命令编码器中：

computeEncoder.dispatchThreadgroups（threadgroupSize，threadsPerThreadgroup：threadsPerThreadgroup）

这就是 CPU 方面所需的全部设置。其余的在 GPU 端设置。

## 在内核函数内的网格中寻找方向

在主代码中，设置每个线程组的线程数以及线程数

每个网格的线程组。当你对工作网格进行编码时，这些会被传递。你还需要传入网格中当前线程的位置：

void kernel myKernel( uint2 S [[threads_per_threadgroup]], uint2 W [[threadgroups_per_grid]], uint2 z [[thread_position_in_grid]]) { }

这类似于片段着色器中跟踪当前正在处理的像素的参数。你不负责计算当前线程在网格或其各自线程组中的位置，但你可以通过向内核函数添加具有适当属性的参数来请求这些值。

## 在内核函数中读写资源

与使用渲染命令函数一样，你需要协调 CPU 和 GPU 之间的资源。如果你还记得前面的章节，Metal 使用参数表（如图 15.4 所示）来保存 CPU 和 GPU 之间共享的资源。在渲染编码器中，可以对三种类型的数据进行编码。对于计算编码器，还有一个附加参数类别。

<Figure
  src={require("../figures/045.jpg")}
  num="15.4"
  desc="计算编码器参数表"
/>

计算管道中 CPU 和 GPU 之间可以共享四种数据：

- 缓冲区
- 纹理
- 采样器
- 线程组内存

_线程组内存_ 是一个新类别。你可以在其中拥有的最大条目数

参数表的线程组内存部分为 31。在这些线程组中，iOS 上每个线程组最多有 512 个线程。在 macOS 上这扩展到 1024 个线程。参数表的最大总线程组内存分配为 16,352 字节。在 macOS 上，这一数字翻倍至 32 KB。在两个操作系统上，这些字节必须分解为 16 字节的块。

你将在第 16 章中了解有关线程和线程组管理的更多信息。

## 概括

渲染命令编码器和计算命令编码器的相似之处多于不同之处。自平台推出以来，计算编码器首次允许你在 iOS 上进行通用 GPU 编程。计算编码器允许你利用并行计算而不仅仅是并发。在 GPU 上，由于 CPU 和 GPU 之间的架构差异，你可以进行高性能的数据处理和数学运算。

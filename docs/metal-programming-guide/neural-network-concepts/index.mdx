# 神经网络概念

<ToBePolishedAfterTranslation />

<Wisdom
  words="你不应该制造一个与人类思想相似的机器。"
  author="Orange Catholic Bible"
/>

我们面临的最大的哲学问题之一是什么使我们成为人类。人工智能的圣杯是创建一个能够模仿人类思维的计算机系统，使其与真实事物无法区分。为了开始尝试这项任务，我们需要了解我们的大脑如何学习和运作，并找到一种在软件中模仿这个过程的方法。这是一个很大的、令人身临其境的主题，但本章介绍如何解决这个问题。

## 神经网络概述

思考是什么意思？你的大脑是一个感觉输入设备，不断处理如何对周围的世界做出反应。你听到地下室传来一声巨响。是潜行者吗？是你的猫打翻了盒子吗？这个盒子是不是很重要的东西，比如你祖母的传家宝瓷器套装？你最初会感到恐慌，因为你想象了所有最坏的情况，但当你处理声音时，你会忽视最令人震惊的可能性，并认为这没什么值得担心的。所有这些想法和过程在一秒钟内开始并完成。

神经网络编程模仿了这个过程。它采用一系列具有加权值的输入，评估二元问题，并返回正值或负值。以许多计算机程序员面临的一个常见问题为例：我应该搬到旧金山吗？有很多不同的点需要考虑：生活成本更高，但可以通过增加的工资来抵消。旧金山拥有充满活力的开发者社区。天气气候温和，但要担心地震。有健全的公共交通系统。然而，你可能喜欢开车上班，而通勤时间可能会成为一个问题。

诸如此类的问题可以通过神经网络来建模。每个考虑因素都是一个输入。因为每个人都是不同的并且有不同的优先级，所以每个考虑因素都有不同的权重。对于某些人来说，参与技术创新比任何其它考虑因素都更重要。对于其它人来说，这种福利并不重要，而且一小时通勤的前景是站不住脚的。考虑到绝对不会搬到旧金山的人和仍在努力搬到旧金山的大量人之间的分歧，显然这个问题没有"正确"的答案。因为不同的人有不同的优先事项，所以人们会得出自己的个人结论。

## 神经网络组件

神经网络由构成层的节点图组成，如图 19.1 所示。这些节点层大致分为三种类型之一：输入、输出和隐藏。输入层是各种输入和权重的集合。在搬迁到旧金山的示例中，每个考虑因素都是输入层中的一个节点。根据每个考虑因素对你的重要性，每个节点都会被赋予不同的权重。输出层由代表输出（是或否）的单个节点组成。

<Figure
  src={require("./19_1.jpg")}
  num="19.1"
  desc="神经网络的一般表示"
  size={420}
  edge="white"
/>

隐藏层听起来超级神秘，但它只是不是直接输入或输出的任何节点层。隐藏层是所有神经网络优点所在。这是将算法合并到数据输入中以及对数据进行细化的地方。把它想象成一个数据工厂。输入被传递到处理的第一阶段。该数据被传递到下一个，依此类推，直到输出结束。这种类型的网络称为 _前馈神经网络_。循环的神经网络称为 _循环神经网络_。循环神经网络现在可以在 Metal 2 框架中使用，但它们超出了本书的范围。我们现在专注于前馈神经网络。本章后面将更详细地描述不同类型的隐藏层。

### 感知器

有几种不同类型的人工神经元。最早、最原始的人工神经元之一是 _感知器_。感知器自 20 世纪 50 年代就已出现。感知器接受一系列输入和权重，并输出二进制响应（1 或 0），如图 19.2 所示。神经元的输出取决于加权和是否小于或大于某个阈值。

<Figure
  src={require("./19_2.jpg")}
  num="19.2"
  desc="感知器的表示"
  size={320}
  edge="white"
/>

感知器的每个输入也是一个二进制值，要么是 1，要么是 0。让我们看一下搬迁到旧金山的示例，以解释感知器的工作原理。假设感知器有以下输入：

- 我的通勤时间少于一个小时吗？
- 我的年薪是否超过 160,000 美元？
- 我是否有其它开发者的社交网络可以与之共度时光？- 我需要担心宠物吗？

出于本示例的目的，假设 1 是你想要搬迁到旧金山的积极迹象。在这个例子中，你的通勤时间是一个半小时，所以第一个输入是 0。然而，你的工作机会是每年 160,000 美元，所以第二个输入是 1。你已经知道你将拥有一个很棒的社交网络开发者，所以第三个输入是 1。在这个例子中你没有宠物，所以因为你不必担心试图找到一个可以养宠物的地方，所以最后一个输入也是 1。

如果你只是简单地列出优点和缺点，你显然会选择搬迁，因为你有三个优点，只有一个缺点。但事实并非如此。假装你真的非常讨厌通勤。对你来说，一个多小时的通勤时间完全是一个大问题。如果你给该神经元的权重为 10，而每个其它输入的权重为 1，那么该输入的结果将完全超出网络中的所有其它考虑因素。输入的总和为：

```cpp
(10 * 0) + (1 * 1) + (1 * 1) + (1 * 1) = 3
```

现在，这个结果没有任何意义，因为你还没有设置阈值。我们将阈值设置为 5。输入的总和必须大于 5。如果总和恰好为 5，则返回 false。阈值设置得足够低，因此如果你的通勤时间超过一个小时，你永远不会超过阈值。这可能是你想要的，但如果不是，则可以相应地调整权重和阈值。

### 偏见

除了阈值之外，还有另一种方法可以衡量一组输入的结果是 0 还是 1。这种方法被称为 _bias_。偏差是衡量感知器启动难易程度的指标。就像在生活中一样，偏差越大，获得期望结果的可能性就越大——在本例中，触发并返回 1 而不是 0。

<Figure src={require("./19_a.jpg")} size={320} edge="white" />

该方程与阈值化的方程略有不同。阈值始终为 0，而不是设置阈值。权重可以指定负权重和正权重。与之前一样，每个感知器值乘以权重并求和，但除此之外，还在方程中添加了偏差值。

让我们回到搬迁到旧金山的例子。尽管有很多充分的理由不搬迁到旧金山，但你内心深处确实想搬迁。因此，你可以调整权重和偏差以反映现实。理论上你可以只改变权重，但这会导致你得到的结果发生一些不和谐和极端的变化。在下一节有关 S 形神经元的内容中，你将了解为什么这种区别很重要。

让我们重新评估一下旧金山的例子。我们的新权重可能如下所示：

- **通勤**：-5
- **工资**：-1
- **社交网络**：-1
- **宠物**：-1

现在，你将分配 0，而不是分配 1 给会导致神经元激发的输入。通过我们的新方程，我们得到：

```cpp
(-5 * 1) + (-1 * 0) + (-1 * 0) + (-1 * 0) = -5
```

这仍然不会导致神经元激发，但如果你创建 6 的偏差并将其添加到 -5，你就会得到一个正值，并且它会导致神经元激发。这会创建一个不太极端的网络。如果多个神经元值发生变化，它仍然可能会失败，但它确实提供了更大的灵活性来更改权重和值，而不会导致结果波动太快。

到目前为止，这很酷，但你所做的只是创建一个巨大的决策树结构。这在计算机科学中已经存在。你正在手工编码你的权重和偏差。如果你想输入具有不同值的图像数据集，会发生什么情况？如果你想利用 GPU 实际从数据集中学习该怎么办？决策树结构不适合你，所以你需要一种新型的人工神经元，如图 19.3 所示。

<Figure
  src={require("./19_3.jpg")}
  num="19.3"
  desc="可线性分离的数据集"
  size={320}
  edge="white"
/>

### 乙状结肠神经元

感知器本质上是有限制的。当你有线性数据时，它们可以很好地工作，但当你有非线性数据时，它们就不行了。假设你有两个彼此合不来的朋友。你正在决定是否要去参加聚会。你和你的两个朋友都被邀请了，但每次他们一起参加聚会时，他们都会大吵一架。如果只有其中一个人参加，你会很高兴去参加聚会，但如果两人都参加，你就不会。如果他们都要去，你就不想去，因为你不想卷入他们的戏剧之中。如果他们都不去，你就不会真正认识那里的其它人，你也不会想去躲在厨房里与当地的宠物交朋友。

这种困境被称为"异或"或"异或"问题。无法使用感知器在真值表中线性分离这些条件，如图 19.4 所示。这就是 _sigmoid 神经元_ 发挥作用的地方。

<Figure
  src={require("./19_4.jpg")}
  num="19.4"
  desc="无法线性分离的数据集"
  size={320}
  edge="white"
/>

S 形神经元是非线性的。线性只是意味着数量以稳定的速度增加。如果你还记得高中代数，当你绘制 _y_ = _x_ 方程时，斜率是 1。直线总是上升一个单位，并且永远超过一个单位。这个概念很简单，但它并不代表自然现象 S 型神经元的方程如下所示，如图 19.5 所示。

<Figure src={require("./19_b.jpg")} size={120} edge="white" />

<Figure
  src={require("./19_5.jpg")}
  num="19.5"
  desc="线性分析与 sigmoid 分析之间的比较"
  size={320}
  edge="white"
/>

在许多情况下，你需要细致地读取数据。关于搬迁到旧金山的感知器示例有点粗糙。如果提供的薪水是 159,000 美元而不是 160,000 美元，你的感知器将返回 0，即使你可能并不真正关心缺少的 1000 美元。总数足够接近。通勤时间也没有回旋余地。一小时零五分钟的通勤与三小时的通勤具有相同的结果和权重。即使你想要的通勤时间少于一小时，你也可能愿意接受仅多几分钟的时间。使用感知器，你无法生成梯度来表示足够接近或明显超出你想要的范围的结果。

### 学习和培训

神经网络最大的希望是创建一个能够学习的系统。微妙地改变权重和偏差会对结果产生很大的影响。在实际实施中，你正在训练一个数据模型，以了解哈巴狗的图片是哈巴狗而不是热狗。

在旧金山的例子中，你工作时假设你亲自输入权重和偏差。一个能够学习的理论和实践模型将能够扫描硅谷当前职位空缺以及预期居住空间的大型数据库，并寻找适合你个人需求的工作和居住空间组合。为此，模型需要了解什么是好的组合，什么是坏的组合。

训练神经网络的一般方法有以下三种：

- _监督学习_ 是目前你可能最熟悉和最常用的学习方式。监督学习需要获取带标签的图像数据集，并教导网络根据同一对象的多个图像来识别对象。训练模型后，你可以将其引入训练对象的图像。根据你输入的猜测是否正确的输入，模型会进行自我调整。
- _无监督学习_ 需要从大数据集中推断信息。这是一种存在主义学习方式，因为没有正确或错误的答案。该网络只是分析大量数据来发现相似之处。这种学习方式对于那些希望瞄准最有可能投票给他们的人的政党来说是有效的。该网络可以获取大量人口统计数据并寻找看似不相关的数据。
- _强化学习_ 是关于接收基于决策的反馈。假设你是一所大学的招生人员。你可以录取的人数有限，但你无法知道哪些学生真诚地致力于就读你的大学，以及有多少人认为这是他们的保底学校。你希望优化被录取后选择就读你的大学的学生数量。你可以编制一份被录取的学生名单，以找到最有可能进入你的大学的共同要素。这将帮助你最大限度地招收最有可能入学的最优秀的学生。

神经网络真正擅长的一件事是模式识别。在第 17 章"机器视觉"中，你了解了一些有关人脸和检测的知识。这是模式匹配的一个例子。查看一千张面孔的数据模型可以开始识别出它们都具有相似的特征，包括两只眼睛和一个鼻子。它可以识别肤色的范围很窄，如果一个物体绝大多数是绿色的，那么它不太可能是一张脸。

### 训练集和反向传播

到目前为止，神经网络完全不知道什么构成正确或错误的答案。如果没有关于猜测是对还是错的反馈，神经网络就无法学习或适应。在监督学习模型中，你利用训练集来教网络如何识别特征。该训练集生成导入到神经网络的数据模型。

### 我可以在 iPhone 上训练学习集吗？

关于 Metal 的一个常见问题是是否可以在 iPhone 上训练数据模型。最简洁的答案是不。更复杂的答案是详细说明训练集的含义。

训练数据模型需要大量训练图像的集合。最流行和最熟悉的训练集之一是 ImageNet 训练集。除了存在知识产权许可问题外，ImageNet 训练集为 190 GB。这对于市场上绝大多数 iOS 设备来说太大了。

除此之外，iPhone 甚至大多数 Mac 设备上的 GPU 的能力都太弱，无法在合理的时间内训练数据模型 NVidia GTX 1080 是市场上最强大的 GPU 之一。这是一个不断变化的目标，因为 GPU 技术发展非常迅速。

苹果的技术有很多，但可定制并不是其中之一。该硬件针对的是并不真正想要或不需要 600 美元外部 GPU 的一般市场。随着 Metal 2 中外部图形开发套件的引入，这种情况开始发生变化，但一般来说，如果你构建一台专门用于训练数据模型的计算机，而不是临时装备你的 MacBook Pro，你会获得更多收益训练数据模型。

训练过程如下。网络会收到一张带标签的图像，并被要求对其进行分析并返回对该图像代表的内容的猜测。有两种选择。网络可能回答正确，也可能回答错误。如果网络没有正确应答，则结果是错误。该错误使用称为"反向传播"的方法反馈到网络中。网络在内部调整其权重和偏差，并尝试最大程度地减少该学习集中错误猜测的数量。

将反向传播想象为 SAT 样本测试。你可以一遍又一遍地进行练习测试，获得有关你做错的问题以及正确答案的反馈。经过一些这样的测试后，你会注意到编写测试的人所设置的常见陷阱中出现了某些模式。在做了足够多的练习测试后，你的成功率会大大提高，但这只有在你得到关于你做错的问题和正确答案的反馈时才有效。

## 神经网络架构

本章的第一部分介绍了神经网络的各个组成部分。神经网络不仅仅是这些组件。这就是它们创建网络的方式。本节讨论如何将所有这些组件组合在一起来创建神经网络。

图 19.6 展示了一个简单的三层神经网络，其隐藏层由 sigmoid 神经元组成。有两个输入、三个隐藏节点和一个输出。这里需要注意的一件事是，两个输入节点都连接到所有三个隐藏节点，并且所有三个隐藏节点都连接到输出。这是 _全连接神经网络_ 的示例。

<Figure
  src={require("./19_6.jpg")}
  num="19.6"
  desc="一个简单的三层神经网络，具有两个输入和一个输出"
  size={420}
  edge="white"
/>

这个神经网络有点像一台机器。输出节点的输出根据输入的输入而变化。这里不存储任何值。它们是短暂的，并且会根据输入而变化。

在本章前面，你了解了权重和偏差。在粗略的示例中，你手动设置它们。你还了解了经过训练的数据模型。这些在这里发挥作用。为了确定输出神经元是否激发，将输入乘以隐藏层中的权重和偏差。这些权重和偏差由经过训练的数据模型确定。这就是有一个关于数据科学家无法解释结果如何发生的笑话的原因之一。神经网络的训练以一种你不一定能看到它在做什么的方式处理这些数据。

该神经网络的代码如下：

```swift
// pseudocode
func sigmoid(x) {
  return 1 / (1 + exp(-x))
}
func f(X1, X2) {
    H1 = sigmoid( X1*Wxh[1,1] + X2*Wxh[2,1] + bh1 )
    H2 = sigmoid( X1*Wxh[1,2] + X2*Wxh[2,2] + bh2 )
    H3 = sigmoid( X1*Wxh[1,3] + X2*Wxh[2,3] + bh3 )
    O1 = sigmoid( H1*Who[1] + H2*Who[2] + H3*Who[3] +   bo1 )
    return O1
}
```

该函数接受两个节点输入并使用它们来计算隐藏层的值。隐藏层是使用顶部的 sigmoid 函数计算的。该函数将 1 加上负输入的指数除以 1，从而创建熟悉的 S 形曲线，其中值在函数的开头和结尾快速增加。

`Wxh[1,1]` 表示第一个输入层和第一个隐藏层之间的权重 `[n, n]` 值表示相关的输入节点和隐藏节点。第一个、第二个和第三个隐藏节点之间的权重不同，因此你需要指定要添加到每个方程中的关系 bh1 表示第一个隐藏节点的偏差。类似地，bh2 是偏置

第二个隐藏节点，bh3 是第三个隐藏节点的偏差 who 代表隐藏层和输出层之间的权重。由于只有一个输出，因此只指定一个节点，即隐藏节点。底部的输出返回 0 到 1 之间的值。分析该值以查看它是否达到某个阈值以及输出是否触发。

这种方法工作正常，但似乎有很多重叠的代码。对于小型神经网络来说这不是问题，但是当你有数百个节点和数十层时，它就变得站不住脚了。这个问题有一个解决方案，就是第 20 章"卷积神经网络"的主题。

## 概括

神经网络模拟人脑的学习方式。有一些称为感知器的原始神经元是二元的。还有一些线性神经元被称为"乙状结肠神经元"，它们更灵活，并且返回更大的细微差别。网络架构涉及如何连接所有这些节点以及如何对它们的输入进行加权和相互训练。本章重点介绍全连接神经网络，这并不是实现神经网络的唯一方法。
